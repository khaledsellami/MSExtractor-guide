<a name="readme-top"></a>

<h3 align="center">MSExtractor</h3>

  <p align="center">
    This project is an implementation of the MSExtractor decomposition approach as described in the paper "Improving microservices 
    extraction using evolutionary search" <a href="https://doi.org/10.1016/j.infsof.2022.106996">(2022)</a>.

  </p>



<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li>
      <a href="#usage">Usage</a>
      <ul>
        <li><a href="#server">Starting the server</a></li>
        <li><a href="#cli">Using the MSExtractor CLI</a></li>
        <li><a href="#cli">Using a third-party analysis tool</a></li>
      </ul>
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#references">References</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Project

This project is an implementation of the MSExtractor decomposition approach as described in the paper 
"Improving microservices extraction using evolutionary search" [[1]](#1).

MSExtractor is a decomposition tool that analyzes the source code of a monolithic Java application and suggests the 
recommended microservices for each class in the system using the evolutionary algorithm IBEA 
(Indicator-Based Evolutionary Algorithm). 

The MSExtractor docker image contains the code that only handles the decomposition of the monolithic application. 
However, the analysis of the source code has to be done by another tool. In this project, we share two additional 
services that can used to use MSExtractor in full. Otherwise, it is possible to use your own tool but the input to 
MSExtractor has to conform to the required types and structure. 


## Getting Started

Running MSExtractor and its services only requires Docker. However, Python is useful for the helper scripts.

### Prerequisites

This is an example of how to list things you need to use the software and how to install them.
* Docker
* Python 3.6

### Installation

1. Clone the repo
   ```sh
   git clone https://github.com/khaledsellami/MSExtractor-guide.git
   ```
2. Install the Python libraries
   ```sh
   cd MSExtractor-guide/
   pip install -r requirements.txt
   ```



<!-- USAGE EXAMPLES -->
## Usage
The current MSExtractor image can be launched as a server or can be used to generate a single decomposition through 
the command line interface.


### Starting the server
We can run MSExtractor as a gRPC server. In this case, the decomposition can be generated by using a gRPC client using 
the protobuf file "msextractor.proto". In this case, MSExtractor will be able to download and decompose the source code 
of the monolithic directly from its Github repository.

To start the server you simply need to use the docker-compose.yml file:
   ```sh
   docker compose up
   ```

The server will be accessible from http://localhost:50060


### Using the MSExtractor CLI
In this case, the analysis data has to be generated using the analysis and parsing tools images locally and then given 
to MSExtractor as input.

1. Select the source code of the monolithic application to decompose:  
    ```sh
   export MONOPATH="path_to_your_app_src"
   export APPNAME="name_of_the_app"
   ```
2. Use the analysis tool to generate the class and method metadata:
    ```sh
   mkdir -p ./temp_data/$APPNAME/static_analysis
   docker run -it --rm -v $MONOPATH:/input/ -v ./temp_data/$APPNAME/static_analysis:/output/ dcalsel/decomp-java-analysis-service:latest analyze $APPNAME -p /input -o /output
   ```
3. Use the parsing tool to extract the call and semantic data:
    ```sh
   mkdir -p ./temp_data/$APPNAME/parsing_results
   docker run -it --rm -v ./temp_data/$APPNAME/static_analysis/$APPNAME:/input -v ./temp_data/$APPNAME/parsing_results/:/output/ dcalsel/decomp-parsing-service:latest parse $APPNAME -f CSV -d /input/ -o /output/
   ```
4. Prepare the data for MSExtractor:
    ```sh
   python to_msextractor.py --data ./temp_data/$APPNAME/parsing_results/$APPNAME --output ./temp_data/
   ```
5. Create the decomposition with MSExtractor:
    ```sh
   mkdir -p ./temp_data/decompositions
   docker run -it --rm -v ./temp_data/decompositions/:/output -v ./temp_data:/data dcalsel/msextractor:latest decompose $APPNAME --data /data --output /output
   ```
6. The output of MSExtractor can be found in the file "decomposition.json" in the output directly. For example, the auto-generated name of the run is "name_of_the_app_202402021000", the decomposition as well as additional metadata can be found here:
    ```sh
   ls ./temp_data/decompositions/$APPNAME
   cat ./temp_data/decompositions/$APPNAME/name_of_the_app_202402021000/decomposition.json
   ```

Additional details about the CLI can be inspected using the following command:
```sh
   docker run -it --rm dcalsel/msextractor:latest decompose --help
```


### Using a third-party analysis tool
It is possible to use MSExtractor with a different analysis tool with MSExtractor. In this case, MSExtractor can be used in this way:
```sh
   export APPNAME="name_of_the_app"
   mkdir -p ./temp_data/decompositions
   docker run -it --rm -v ./temp_data/decompositions/:/output -v ./path_to_my_data:/data dcalsel/msextractor:latest decompose $APPNAME --data /data --output /output
```

where "path_to_my_data" is the folder that contains all of the required input. The folder must contain the following elements:
```text
   path_to_my_data/
   └── name_of_the_app/
      ├── semantic_data/
      │   ├── class_names.json: a list of strings representing the list of class names in their order in tfidf.npy
      │   └── class_tfidf.npy: a numpy NxM matrix representing the TF-IDF vectors of each class where N is the number of classes and M is the size of the vocabulary
      └── structural_data/
          ├── class_calls.npy: a numpy NxM matrix representing the calls from each class to the others where N is the number of classes
          └── class_names.json: a list of strings representing the list of class names in their order in class_calls.npy
```





<!-- LICENSE -->
## License

Distributed under the GNU GPL-3.0 License. See `LICENSE` for more information.




<!-- REFERENCES -->
## References

<a id="1">[1]</a> 
Khaled Sellami, Ali Ouni, Mohamed Aymen Saied, Salah Bouktif, & Mohamed Wiem Mkaouer (2022). 
Improving microservices extraction using evolutionary search. 
Information and Software Technology, 151, 106996.


<p align="right">(<a href="#readme-top">back to top</a>)</p>

